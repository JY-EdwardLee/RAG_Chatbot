{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O_zgP34Gt0K"
      },
      "source": [
        "### **Content License Agreement**\n",
        "\n",
        "<font color='red'><b>**WARNING**</b></font> : 본 자료는 삼성 청년 SW아카데미의 컨텐츠 자산으로, 보안서약서에 의거하여 어떠한 사유로도 임의로 복사, 촬영, 녹음, 복제, 보관, 전송하거나 허가 받지 않은 저장매체를 이용한 보관, 제3자에게 누설, 공개 또는 사용하는 등의 무단 사용 및 불법 배포 시 법적 조치를 받을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBMRC-8eG2Fh"
      },
      "source": [
        "### **Objectives**\n",
        "LLM을 활용하여 제품 메뉴얼 정보를 기반으로 QA Pair를 자동 생성을 통해 데이터셋 구축의 실제 과정을 체험합니다. 이를 통해 데이터 구성능력을 높이고, QA Pair 자동 생성의 실무적 활용법을 다뤄볼 예정입니다.\n",
        "1. 실습 개요\n",
        "    - LangChain 라이브러리를 사용하여 제품 메뉴얼에서 QA Pair를 자동으로 생성하고 데이터셋을 구축하는 실습\n",
        "    - 고객 사용 사례를 기반으로 질문 유형을 분류하여 데이터셋을 체계화\n",
        "    - 생성된 데이터셋에서 중복을 제거하고 품질을 평가하여 데이터셋을 정제\n",
        "\n",
        "2. 실습 진행 목적 및 배경\n",
        "    - **목적**: LLM을 활용한 QA Pair 자동 생성 및 데이터셋 구축 과정을 실습하여, 데이터 구성 능력을 향상시키고 실무적인 활용법을 익힙니다.\n",
        "    - **배경**: 최근 LLM 기술의 발전으로 QA 챗봇 등 다양한 서비스에서 자동화된 데이터셋 구축의 필요성이 증가하고 있습니다. 이 실습을 통해 이러한 트렌드에 대응하고 실무에 적용 가능한 역량을 강화합니다.\n",
        "3. 실습 수행으로 얻어갈 수 있는 역량\n",
        "    - **데이터 구성 능력**: 제품 메뉴얼과 같은 비정형 데이터에서 QA Pair를 추출하고 정제하는 능력을 향상시킵니다.\n",
        "    - **LLM 활용 능력**: LangChain과 같은 LLM 프레임워크를 활용하여 QA Pair 생성을 자동화하는 방법을 익힙니다.\n",
        "    - **데이터 품질 평가**: 생성된 데이터셋의 품질을 평가하고 개선하는 방법을 학습합니다.\n",
        "    - **실무 적용 능력**: 실제 서비스에 적용 가능한 QA 데이터셋 구축 및 활용 경험을 얻습니다.\n",
        "\n",
        "4. 데이터셋 개요\n",
        "    - 1강 실습에서 크롤링하여 수집한 데이터셋을 활용합니다.\n",
        "5. 실습 핵심 내용\n",
        "    - **LLM 기반 QA Pair 자동 생성**: LangChain을 활용하여 제품 메뉴얼에서 QA Pair를 자동으로 생성합니다.\n",
        "    - **고객 사용 사례 기반 질문 유형화**: 고객의 사용 사례를 분석하여 질문 유형을 분류하고, 이를 기반으로 QA Pair를 생성합니다.\n",
        "    - **데이터셋 정제 및 품질 평가**: 생성된 데이터셋에서 중복 제거 및 품질 평가를 수행하여 데이터셋의 완성도를 높입니다.\n",
        "    - **실무 적용**: 구축된 QA 데이터셋을 실제 서비스에 적용하여 성능을 향상시키는 방안을 모색합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhMJqtdyG40p"
      },
      "source": [
        "### **Prerequisites**\n",
        "\n",
        "```\n",
        "langchain_community == 0.3.9\n",
        "langchain == 0.3.9\n",
        "pymupdf == 1.24.14\n",
        "datasets  ==  3.1.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0aImYaqMmMO"
      },
      "source": [
        "### 필요 Library 설치 (#langchain #langchain-community #pymupdf)\n",
        "\n",
        "코드에서 사용할 라이브러리들을 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arFRlo9ZG6pk",
        "outputId": "ae8823c9-d1a1-4ff5-eb8f-04cf2edd7cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChNFZJmBil4p",
        "outputId": "d599ca52-300c-4e44-86cf-4ec7380930f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-community pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh2aRbNABK9l",
        "outputId": "894094b3-6131-4f41-810c-313f82e97816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: httpx<0.28 in /opt/miniconda3/lib/python3.13/site-packages (0.27.2)\n",
            "Requirement already satisfied: anyio in /opt/miniconda3/lib/python3.13/site-packages (from httpx<0.28) (4.9.0)\n",
            "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.13/site-packages (from httpx<0.28) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.13/site-packages (from httpx<0.28) (1.0.9)\n",
            "Requirement already satisfied: idna in /opt/miniconda3/lib/python3.13/site-packages (from httpx<0.28) (3.7)\n",
            "Requirement already satisfied: sniffio in /opt/miniconda3/lib/python3.13/site-packages (from httpx<0.28) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.28) (0.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade \"httpx<0.28\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ust6iIMFhKOD",
        "outputId": "814dba28-e85a-46c0-f739-e36a446ecb05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: koreanize-matplotlib in /opt/miniconda3/lib/python3.13/site-packages (0.1.1)\n",
            "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.13/site-packages (from koreanize-matplotlib) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (2.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->koreanize-matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->koreanize-matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install koreanize-matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vj7_FIW2igO",
        "outputId": "ff138f4f-189c-4da9-d5f2-ff1df546e189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/miniconda3/lib/python3.13/site-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (2.3.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/miniconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (0.33.1)\n",
            "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/miniconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /opt/miniconda3/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/miniconda3/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: openai in /opt/miniconda3/lib/python3.13/site-packages (1.91.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/lib/python3.13/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/lib/python3.13/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/lib/python3.13/site-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/lib/python3.13/site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/miniconda3/lib/python3.13/site-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /opt/miniconda3/lib/python3.13/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /opt/miniconda3/lib/python3.13/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/miniconda3/lib/python3.13/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets\n",
        "%pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Cw561HMxwN"
      },
      "source": [
        "## 1. QA Pair 생성 자동화 실습\n",
        "LLM을 활용해 제품 메뉴얼 기반의 QA Pair를 자동으로 생성하는 방법을 학습자가 습득할 수 있도록 돕습니다. 학습자는 고객이 자주 묻는 질문을 미리 예측하고 QA 데이터셋을 구성함으로써, QA 챗봇의 대화 품질을 높이는 실질적인 방법을 배울 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkvrylfgioP6"
      },
      "source": [
        "### **Exercise Overview**\n",
        "- QA Pair 생성 자동화 실습\n",
        "    - 필요 Library 설치 (#langchain #langchain-community #pymupdf)\n",
        "    - `langchain`소개\n",
        "    - `RecursiveCharacterTextSplitter`로 청깅해보기\n",
        "    - `ChatPromptTemplate` 맛보기\n",
        "    - chain으로 component 연결\n",
        "    - prompt 강화로 구조화된 데이터 생성\n",
        "- 고객 사용 사례를 반영한 질문 유형화 실습\n",
        "    - Top-down 고객 사용 사례기반 분류\n",
        "- 데이터셋 정제 및 품질 평가 실습\n",
        "    - `TfidfVectorizer`를 이용하여 중복 제거\n",
        "- (Appendix)`document_loaders` 사용해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI0EiCgm76Uz"
      },
      "source": [
        "## ⭐실습 코드 가이드⭐\n",
        "실습 코드에서 ⭐ **표시된 주석**은 직접 값을 변경하며 결과의 차이를 체험해보는 부분입니다.\n",
        "\n",
        "⭐ 표시가 있는 부분을 집중적으로 실습하며 다양한 변화를 확인해보세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9t4aFNcb7XT"
      },
      "source": [
        "### 1.1 LangChain이란?\n",
        "\n",
        "LangChain은 다양한 자연어 처리(NLP) 작업을 쉽게 처리할 수 있도록 돕는 라이브러리입니다. 주로 텍스트 기반의 작업을 자동화하거나 향상시키는 데 사용됩니다. LangChain은 LLM과 다양한 데이터 소스를 결합하여, 보다 복잡한 질문과 답변 시스템, 텍스트 생성, 정보 추출 등을 쉽게 구현할 수 있도록 지원합니다.\n",
        "\n",
        "LangChain의 주요 기능:\n",
        "- LLM 통합: OpenAI GPT, Solar, HuggingFace 모델 등 여러 LLM을 지원\n",
        "- Chain: 여러 작업을 하나의 프로세스로 연결하여 자동화\n",
        "- Agent: 외부 도구와 상호작용하며 작업을 수행하는 에이전트 지원\n",
        "- Document Loaders: 다양한 형식의 문서에서 데이터를 쉽게 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUvyYVrEK9gB",
        "outputId": "5038ca91-2071-4baf-9598-2a8251bb6c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "langchain_community  ==  0.3.26\n",
            "langchain  ==  0.3.26\n",
            "pymupdf  ==  1.26.1\n",
            "datasets  ==  3.6.0\n"
          ]
        }
      ],
      "source": [
        "import langchain_community\n",
        "import langchain\n",
        "import pymupdf\n",
        "import koreanize_matplotlib\n",
        "import datasets\n",
        "\n",
        "def print_version(lib):\n",
        "    print(lib.__name__, \" == \", lib.__version__)\n",
        "\n",
        "print_version(langchain_community)\n",
        "print_version(langchain)\n",
        "print_version(pymupdf)\n",
        "print_version(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F0sL0hwuJcNr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# from google.colab import userdata\n",
        "\n",
        "api_key = \"up_JS6nndROlwPvo1upTDEGE0iJVAkZK\"  # ex: up_xxxYYYzzzAAAbbbCCC\n",
        "os.environ[\"SOLAR_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6-wzAYUb5s0",
        "outputId": "a0bc4272-2a59-43f4-bc75-ae8cf346b878"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gz/2110lwqd6_n2vrd5_jvwgqmw0000gn/T/ipykernel_39555/804134494.py:3: LangChainDeprecationWarning: The class `SolarChat` was deprecated in LangChain 0.0.34 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-upstage package and should be used instead. To use it run `pip install -U :class:`~langchain-upstage` and import as `from :class:`~langchain_upstage import ChatUpstage``.\n",
            "  llm = SolarChat(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Solar는 라틴어 \"solaris\"에서 유래되었으며, 이는 \"태양\"을 의미하는 \"sol\"에서 파생되었습니다. 따라서 Solar는 \"태양과 관련된\" 또는 \"태양에서 나오는\"을 의미합니다. 이 용어는 태양 에너지나 태양광과 관련된 맥락에서 자주 사용됩니다. 예를 들어, 태양광 발전은 태양 에너지를 전기로 변환하는 과정을 말합니다. 또한, Solar는 회사 이름이나 제품 이름으로도 사용되며, 이 경우 태양의 깨끗하고 재생 가능한 에너지를 상징할 수 있습니다.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 17, 'total_tokens': 129, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'solar-pro', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--a9272fc0-a17d-4e8c-9b28-4e393098ba9f-0')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.chat_models.solar import SolarChat\n",
        "\n",
        "llm = SolarChat(\n",
        "    model=\"solar-pro\",\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.2, # ⭐ temperature를 변경하여 차이를 확인해보세요\n",
        "            }\n",
        ")\n",
        "llm.invoke(\"Solar의 뜻은 무엇인가?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTlNVUKxLq0k"
      },
      "source": [
        "### 1.2 `RecursiveCharacterTextSplitter`로 청깅해보기\n",
        "\n",
        "langchain.text_splitter 모듈에서 제공하는 RecursiveCharacterTextSplitter는 텍스트를 일정한 길이로 나누는 데 유용한 도구입니다. 긴 문서나 텍스트 데이터를 처리할 때, 이 도구는 주어진 길이 제한을 초과하지 않도록 텍스트를 재귀적으로 분할합니다. 이를 통해 텍스트를 LLM이 처리 가능한 크기로 나눌 수 있으며, 문맥이 끊기지 않도록 의미 있는 단위를 유지하는 데 중점을 둡니다. 주요 설정과 사용법에 대해 코드 예시와 함께 소개하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUDk6aUBPJz6"
      },
      "source": [
        "#### 1.2.1 RecursiveCharacterTextSplitter 사용 예시\n",
        "\n",
        "아래는 RecursiveCharacterTextSplitter를 사용하여 1일차에서 업스테이지 DP(Document Parser)를 통해 얻은 content를 chunking을 수행하는 간단한 코드 예시입니다. (모든 데이터를 처리하는 것이 아닌 하나의 셈플 데이터를 처리하는 것으로 진행해보도록 하겠습니다.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt8D8wol4QLh"
      },
      "source": [
        "1일차 실습에서 완성한 전처리 데이터(DP pre-process)인 `processed_data.jsonl`를 다운받아  사용할 경우, <br> 구글드라이브에 (ex. `/content/drive`)에 업로드 후 load_jsonl 함수를 사용하세요.\n",
        "\n",
        "혹은 huggingface의 'lomit/samsung_manual_dp' 데이터셋을 이용하실 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3UvogvS_xOg4"
      },
      "outputs": [],
      "source": [
        "# # 구글드라이브 연동\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xuL_8F7iy2O9"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/Users/ijung-yun/SSAFY/DataTrack/Data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "goSQn6zRJRcX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def load_jsonl(path):\n",
        "    data_list = []\n",
        "    with open(path, \"r\" , encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            data_list.append(json.loads(line))\n",
        "    return data_list\n",
        "\n",
        "data_list = load_jsonl(os.path.join(DATA_DIR, \"processed_data_full.jsonl\"))\n",
        "\n",
        "# # huggingface에 업로드 되어 있는 매뉴얼을 불러오기\n",
        "# from datasets import load_dataset\n",
        "# dataset = load_dataset(\"lomit/samsung_manual_dp\", split=\"train\")\n",
        "# data_list = dataset.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tg9tG43EJtxt"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import re\n",
        "\n",
        "sample_idx = 0\n",
        "sample_data = data_list[sample_idx]\n",
        "\n",
        "\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=2048, # ⭐ chunk_size와 chunk_overlap을 변경하여 생성되는 docs가 어떻게 변하는지 확인해보세요\n",
        "#     chunk_overlap=10, # ⭐\n",
        "#     length_function=len,\n",
        "# )\n",
        "\n",
        "# ⭐ separators의 정규표현식을 사용하여 상황에 맞는 split을 구현해보세요\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n+\"],  # 줄바꿈 기준으로 분할\n",
        "    is_separator_regex=True, # separator가 정규 표현식임을 설정\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=10,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_text(\"\".join(sample_data[\"content\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "H1eERsAvoNa8",
        "outputId": "2137bbbf-f955-4cba-dec3-4b2222d78f73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' ⭐\\n아래 코드는 텍스트를 토큰 단위로 분할하는 방법\\n이번 강의에서 다루지 않았지만, 필요에 따라 토큰 단위로 텍스트를 분할하는 방법도 구현할 수 있습니다.\\n이를 통해 모델이 처리하기 쉽고, 일관된 토큰 길이로 데이터를 나눌 수 있습니다.\\n특히 Tokenizer를 사용하면 단순 문자 단위 분할이 아닌 언어 모델의 토큰 기준으로 분할하는 것이 가능합니다.\\n'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" ⭐\n",
        "아래 코드는 텍스트를 토큰 단위로 분할하는 방법\n",
        "이번 강의에서 다루지 않았지만, 필요에 따라 토큰 단위로 텍스트를 분할하는 방법도 구현할 수 있습니다.\n",
        "이를 통해 모델이 처리하기 쉽고, 일관된 토큰 길이로 데이터를 나눌 수 있습니다.\n",
        "특히 Tokenizer를 사용하면 단순 문자 단위 분할이 아닌 언어 모델의 토큰 기준으로 분할하는 것이 가능합니다.\n",
        "\"\"\"\n",
        "# from tokenizers import Tokenizer\n",
        "# # Tokenizer 로드\n",
        "# tokenizer = Tokenizer.from_pretrained(\"upstage/solar-pro-tokenizer\")\n",
        "\n",
        "# # 토큰 길이 계산 함수\n",
        "# def token_length_function(text: str) -> int:\n",
        "#     \"\"\"\n",
        "#     입력 텍스트를 토큰화하고 토큰 길이를 반환하는 함수\n",
        "#     \"\"\"\n",
        "#     tokens = tokenizer.encode(text)\n",
        "#     return len(tokens.ids)\n",
        "\n",
        "# # RecursiveCharacterTextSplitter 설정\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=1024,  # 토큰 단위 최대 청크 크기\n",
        "#     chunk_overlap=10,  # 청크 중첩 크기\n",
        "#     length_function=token_length_function,  # 토큰 길이를 계산하는 함수\n",
        "#     separators=[\"\\n+\"],  # 줄바꿈 기준으로 분할\n",
        "#     is_separator_regex=True\n",
        "# )\n",
        "\n",
        "# docs = text_splitter.split_text(\"\".join(sample_data[\"content\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyHAJtErOfwq"
      },
      "source": [
        "#### 1.2.2 주요 설정 및 기능\n",
        "\n",
        "\t• chunk_size: 텍스트 조각의 최대 길이를 설정합니다. 길이가 초과되지 않도록 재귀적으로 분할합니다.\n",
        "\t• chunk_overlap: 조각 간 겹치는 부분의 길이를 지정합니다. 이를 통해 문맥이 잘리지 않도록 보장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZIh248bO9Cg"
      },
      "source": [
        "#### 1.2.3. 출력 결과 예시\n",
        "\n",
        "위의 코드 실행 시 다음과 같이 텍스트가 조각으로 나뉩니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8XQRywPO1Vd",
        "outputId": "cf67eab4-2637-424a-a8e7-a59cc605181f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['SAMSUNGPyKOBOACTBO\\n�O�b3OBATE��!image\\nSM-A035F/DS\\nRussian. Rev.1.0 www.samsung.comCo�ep�aH�eOCHOBHble CBe�eH�� o6 59 Samsung Notes\\n60 Samsung Members\\nycTpo�cTBe\\n60 Samsung Global Goals\\n4 �po4T�Te nepe� �C�O�b30BaH�eM\\n60 Samsung TV Plus\\n6 YC�OB�� neperpeBa ycTpo�CTBa N BO3MO*Hble Shop\\n60 Galaxy\\npeweH��\\n61 Ka�eH�apb\\n10 ������� B�� ycTpo�cTBa N ⌀yHKUNN\\n61 Ha�oM�HaH��\\n14 3ap��ka aKKyMy��Topa\\n63 3ByKO3a��cb\\n16 SIM- N USIM-kapTa (KapTa nano-SIM)\\n63 Mo� �a��bl\\n17 KapTa �aM�T� (microSD)\\n63 4acbl\\n19 �������H�e N BbIK����eH�e ycTpo�cTBa\\n64 Ka�bky��Top\\n20 Ha�a�bHa� HacTpo�Ka\\n64 O6MeH co�ep*�MbIM\\n21 ������� 3a��cb Samsung\\n65 �p��o�eH�� Google\\n22 �epeHoc �aHHbIX C npeAbiAywero ycTpo�CTBa\\n(Smart Switch)\\n24 On�caH�e �yHK��� �KpaHa\\n32 �aHe�b yBeAoM�eH�� HacTpo�K�\\n33 BBOA TeKCTa BBe�eH�e\\n66\\n66 Samsung account\\n66 �o�K����eH��\\n�p��o�eH�� N �YHKUNN 68 Wi-Fi\\n69 Bluetooth\\n36 ycTaHOBKa N y�a�eH�e np��o�eH��\\n70 �KOHOM�� Tpa����\\n37 Te�e⌀oH\\n71 To�bKO MOO��bHble �aHHble\\n40 KOHTaKTbI\\n71 Mo6��bHa� TO4Ka �ocTyna\\n42 Coo6�eH��',\n",
              " '72 Apyr�e HacTpo�K�\\n43 NHTepHeT\\n44 Kamepa\\n53 「a�epe�\\n57 Hecko�bKO OKOH2Co�ep*aH�e73 3ByKN N ��������\\n73 Ka�ecTBO 3ByKa N �⌀⌀ektbl\\n74 Pa3�e�bHbI� BbIBOA 3ByKa\\n74 yBe�oM�eH��\\n74 A�cn�e�\\n75 O6o�\\n75 TeMbI\\n75 「�aBHbI� �����\\n76 �kpaH 6�oK�poBK�\\n76 Smart Lock\\n77 b�oMeTp�� N 6e30�acHOCTb\\n77 Pac�o3HaBaH�e ���a\\n79 KoH���eH��a�bHOCTb\\n80 �oka���\\n80 Google\\n80 y4eTHble 3a��c� N apx�Ba���\\n81 Samsung Cloud\\n82 Ao�o�H�Te�bHble ⌀yHKUNN\\n83 ABN�eH�� N �ecTbl\\n83 ABO�HO� �po���b np��o�eH��\\n84 �c�o�b30BaH�e ycTpo�CTBa N po��Te�bcK��\\nKOHTpo�b\\n84 O6c�y����H�e ycTpo�CTBa\\n84 O�T�M�3���� ycTpo�cTBa\\n85 baTape�\\n85 �aM�Tb\\n85 O3y\\n86 3����� ycTpo�CTBa\\n86 �p��o�eH��\\n86 O6��e HacTpo�K�\\n87 Cne��a�bHble BO3MO*HOCT�\\n88 O6HOB�eH�e �o\\n88 y�a�eHHa� �o��ep*ka\\n89 CBe�eH�� o Te�e⌀oHe�p��o�eH�e90 ycTpaHeH�e He�o�a�oK3OCHOBHble CBe�eH�� o6\\nycTpo�CTBe�po4T�Te �epeA �C�O�b30BaH�eM�o�a�y�cTa, B 4e��x npaB��bHoro N 6e3onacHoro �C�O�b30BaH�� ycTpo�cTBa, �pe*�e 4eM np�cTynaTb K',\n",
              " 'pa6oTe C H�M, N3y��Te �TO pyKOBOACTBO.· �p�Be�eHHble H�*e �������� OCHOBaHbl Ha HacTpo�Kax ycTpo�CTBa �o yMO��aH��.\\n· �p�Be�eHHble CBe�eH�� MO�yT �������� He COOTBeTCTBOBaTb ⌀YHK4��M �aHHoro ycTpo�cTBa. �TO 3�B�C�T\\nOT per�oHa, xapaKTep�CT�K ycTpo�cTBa, nporpaMMHoro o6ec�e�eH�� ��� �OCTaB��Ka yc�yr.\\n· �p� �C�O�b3OBaH�� HeKOTOpbIX np��o�eH�� N�N �yHKU�� ycTpo�CTBy MO�KeT Tpe60BaTbC� �o�K����eH�e\\nK Wi-Fi N�N ��6������ ceT�.\\n· KOHTeHT (BbICOKOKa4eCTBeHHbI� KOHTeHT) C BbICOK�M �oTpe6�eH�eM pecypcoB un N O3y B���eT Ha\\no6�y� �po�3BO��Te�bHOCTb ycTpo�cTBa. �p��o�eH��, �c�o�b3ylo��e TaKo� KOHTeHT, MO�yT pa6oTaTb\\nHeKoppeKTHO B 3aB�C�MOCT� OT xapaKTep�CT�K ycTpo�cTBa N cpe�bl, B KOTOPO� OHO �C�o�b3yeTc�.\\n· KoM�aH�� Samsung He HeCeT OTBeTCTBeHHOCT� 3a HapyweH�� �po�3BO��Te�bHOCT�, Bbl3BaHHble\\nnp��o�eH��M�, BbIny�eHHbIM� He KOM�aH�e� Samsung.\\n· KoM�aH�� Samsung He HeCeT OTBeTCTBeHHOCT� 3a HapyweH�� �po�3BO��Te�bHOCT� N�N COBMeCT�MOCT�,']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g2DZVaMKMEf",
        "outputId": "b5e54a56-b160-4375-c0be-dd1a32d56efb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "148"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6llq3vMwhys8"
      },
      "source": [
        "### 1.3 `ChatPromptTemplate` 맛보기\n",
        "\n",
        "langchain_core.prompts에서 제공하는 **ChatPromptTemplate**는 LangChain에서 대화형 프롬프트를 관리하는 도구로, 여러 메시지를 포함하는 대화형 시스템을 설계할 때 유용합니다. 이를 통해 LLM에게 **시스템 메시지(System message)**와 **사용자 메시지(User message)**를 구분하여 전달할 수 있습니다. 각 메시지의 역할과 차이점에 대해 설명하고, 이를 코드 예시와 함께 소개하겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ungin4jRpe7s"
      },
      "source": [
        "#### 1.3.1. ChatPromptTemplate 사용 예시\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e7jRskrD7iS-"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eOe4fCxc7hKq"
      },
      "outputs": [],
      "source": [
        "# 전처리가된 데이터 중에서 product_name가 \"\"인 경우 llm을 통해 product_name을 뽑아냅니다.\n",
        "if sample_data[\"product_name\"] == \"\":\n",
        "    extract_product_name_template = ChatPromptTemplate([\n",
        "        (\"system\", \"\"\"[제품 매뉴얼 첫 페이지]에서 제품 이름만 추출하라. 예제는 다음과 같다.  {product_name_list}\"\"\"),\n",
        "        (\"user\", \"\"\"제품 매뉴얼 첫 페이지 : {first_page}\"\"\"), # 보통 첫번째 페이지에서 \"제품 이름\"이 있으니 첫번째 docs만 이용하여 \"제품 이름\"을 추출한다.\n",
        "    ])\n",
        "    product_name_list = [\"SAMSUNG Galaxy Z Fold3\", \"SAMSUNG Galaxy Z Flip3\", \"Samsung Galaxy S23\"]\n",
        "    result = llm.invoke(extract_product_name_template.format(product_name_list=product_name_list, first_page=docs[0]))\n",
        "    title = result.content\n",
        "\n",
        "else:\n",
        "    # title = \"SAMSUNG Galaxy Z Fold3 I Z Flip3 5G User manual\"\n",
        "    title = sample_data['product_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uel5smGBmoQ",
        "outputId": "ad572dad-8b33-4ba7-86f3-3fd8e4e6e186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Samsung Galaxy Z Fold3 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rYJs2TCHkenH"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"{document_title} 중 한 페이지를 받게된다. 이를 읽고 사용자들이 질문할 만한 질문과 이에 대한 답변을 주어진 정보를 기반하여 만들어라\"\"\"\n",
        "user_prompt = \"\"\"제품 매뉴얼 : {page_content}\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", user_prompt)\n",
        "])\n",
        "\n",
        "result = prompt_template.invoke({\"page_content\": docs[0], \"document_title\": sample_data['product_name']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj57c9FpGHy_",
        "outputId": "b9ca8a7d-2af4-4de3-fbae-7f3e1986bff0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content=' 중 한 페이지를 받게된다. 이를 읽고 사용자들이 질문할 만한 질문과 이에 대한 답변을 주어진 정보를 기반하여 만들어라', additional_kwargs={}, response_metadata={}), HumanMessage(content='제품 매뉴얼 : SAMSUNGPyKOBOACTBO\\n�O�b3OBATE��!image\\nSM-A035F/DS\\nRussian. Rev.1.0 www.samsung.comCo�ep�aH�eOCHOBHble CBe�eH�� o6 59 Samsung Notes\\n60 Samsung Members\\nycTpo�cTBe\\n60 Samsung Global Goals\\n4 �po4T�Te nepe� �C�O�b30BaH�eM\\n60 Samsung TV Plus\\n6 YC�OB�� neperpeBa ycTpo�CTBa N BO3MO*Hble Shop\\n60 Galaxy\\npeweH��\\n61 Ka�eH�apb\\n10 ������� B�� ycTpo�cTBa N ⌀yHKUNN\\n61 Ha�oM�HaH��\\n14 3ap��ka aKKyMy��Topa\\n63 3ByKO3a��cb\\n16 SIM- N USIM-kapTa (KapTa nano-SIM)\\n63 Mo� �a��bl\\n17 KapTa �aM�T� (microSD)\\n63 4acbl\\n19 �������H�e N BbIK����eH�e ycTpo�cTBa\\n64 Ka�bky��Top\\n20 Ha�a�bHa� HacTpo�Ka\\n64 O6MeH co�ep*�MbIM\\n21 ������� 3a��cb Samsung\\n65 �p��o�eH�� Google\\n22 �epeHoc �aHHbIX C npeAbiAywero ycTpo�CTBa\\n(Smart Switch)\\n24 On�caH�e �yHK��� �KpaHa\\n32 �aHe�b yBeAoM�eH�� HacTpo�K�\\n33 BBOA TeKCTa BBe�eH�e\\n66\\n66 Samsung account\\n66 �o�K����eH��\\n�p��o�eH�� N �YHKUNN 68 Wi-Fi\\n69 Bluetooth\\n36 ycTaHOBKa N y�a�eH�e np��o�eH��\\n70 �KOHOM�� Tpa����\\n37 Te�e⌀oH\\n71 To�bKO MOO��bHble �aHHble\\n40 KOHTaKTbI\\n71 Mo6��bHa� TO4Ka �ocTyna\\n42 Coo6�eH��', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6bYUPJ3qgPI"
      },
      "source": [
        "#### 1.3.2. 프롬프트 템플릿에 변수 전달\n",
        "\n",
        "이 코드에서 **ChatPromptTemplate**을 사용하여 시스템 메시지와 사용자 메시지를 구성한 후, invoke() 메서드를 호출하여 실제로 변수를 전달하는 방식입니다. 이 방식은 프롬프트 내에서 동적으로 값을 채워 넣을 수 있게 해줍니다.\n",
        "\n",
        "**시스템 메시지(System Prompt)**\n",
        "\n",
        "```python\n",
        "system_prompt = \"\"\"{document_title} 중 한 페이지를 받게된다.\n",
        "                   이를 읽고 사용자들이 질문할 만한 질문과 이에 대한 응답을 주어진 정보를 기반하여 만들어라\"\"\"\n",
        "```\n",
        "\n",
        "- 여기에서 {document_title}은 변수입니다. 이 변수는 `invoke()` 호출 시 제공되는 데이터에서 \"document_title\" 키에 해당하는 값으로 치환됩니다.\n",
        "- 시스템 메시지는 모델에게 문서의 제목을 제공하며, 그 제목을 바탕으로 페이지를 읽고 질문과 답변을 생성하라는 지침을 줍니다.\n",
        "\n",
        "**사용자 메시지(User Prompt)**\n",
        "```python\n",
        "user_prompt = \"\"\"제품 매뉴얼 : {page_content}\"\"\"\n",
        "```\n",
        "- {page_content}는 변수로, `invoke()` 메서드에서 제공되는 \"page_content\" 값을 기반으로 텍스트가 채워집니다.\n",
        "- 사용자 메시지는 주어진 페이지 내용에 대한 정보를 모델에 전달하며, 이 정보를 바탕으로 모델이 질문과 답변을 만들도록 요청합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPm53UiglZ5l"
      },
      "source": [
        "#### 1.3.3. System 메시지 vs User 메시지\n",
        "\n",
        "- System 메시지(System Message):\n",
        "    - **역할**: 시스템 메시지는 모델에게 작업을 수행하는 데 있어 중요한 지침을 제공합니다. 시스템 메시지는 모델에게 “어떤 방식으로 응답해야 하는지”, “어떤 역할을 해야 하는지” 등을 정의합니다. 예를 들어, 모델에게 친절한 어시스턴트 역할을 하도록 지시하거나, 특정 스타일로 답변하도록 할 수 있습니다.\n",
        "    - **사용 시점**: 시스템 메시지는 시스템 상태를 설정하고 모델에게 대화의 목표나 역할을 명확히 전달하는 데 사용됩니다. 보통 대화의 초기 설정에 해당하며, 대화의 흐름을 제어할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__4rRlCXllXF",
        "outputId": "8a12904f-4254-4ea8-86d7-5b663ceb3613"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SystemMessage(content=' 중 한 페이지를 받게된다. 이를 읽고 사용자들이 질문할 만한 질문과 이에 대한 답변을 주어진 정보를 기반하여 만들어라', additional_kwargs={}, response_metadata={})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.messages[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zjYA2Uqms_k"
      },
      "source": [
        "- User 메시지(User Message):\n",
        "\t- **역할**: 사용자 메시지는 실제 대화에서 사용자가 모델에게 질문하거나 요청하는 내용을 포함합니다. 이 메시지는 모델이 응답해야 할 핵심 내용을 전달합니다. 사용자는 모델에게 특정 작업을 요청하거나 문제를 제시하며, 모델은 이를 바탕으로 답변을 제공합니다.\n",
        "    - **사용 시점**: 사용자 메시지는 대화가 진행되는 동안 사용자가 모델에게 전달하는 메시지로, 모델의 응답을 이끌어내는 주요 정보로 작용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlI-ZLOEmo2M",
        "outputId": "fc802e60-ce2c-4112-cf8b-e17d9ceaea22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HumanMessage(content='제품 매뉴얼 : SAMSUNGPyKOBOACTBO\\n�O�b3OBATE��!image\\nSM-A035F/DS\\nRussian. Rev.1.0 www.samsung.comCo�ep�aH�eOCHOBHble CBe�eH�� o6 59 Samsung Notes\\n60 Samsung Members\\nycTpo�cTBe\\n60 Samsung Global Goals\\n4 �po4T�Te nepe� �C�O�b30BaH�eM\\n60 Samsung TV Plus\\n6 YC�OB�� neperpeBa ycTpo�CTBa N BO3MO*Hble Shop\\n60 Galaxy\\npeweH��\\n61 Ka�eH�apb\\n10 ������� B�� ycTpo�cTBa N ⌀yHKUNN\\n61 Ha�oM�HaH��\\n14 3ap��ka aKKyMy��Topa\\n63 3ByKO3a��cb\\n16 SIM- N USIM-kapTa (KapTa nano-SIM)\\n63 Mo� �a��bl\\n17 KapTa �aM�T� (microSD)\\n63 4acbl\\n19 �������H�e N BbIK����eH�e ycTpo�cTBa\\n64 Ka�bky��Top\\n20 Ha�a�bHa� HacTpo�Ka\\n64 O6MeH co�ep*�MbIM\\n21 ������� 3a��cb Samsung\\n65 �p��o�eH�� Google\\n22 �epeHoc �aHHbIX C npeAbiAywero ycTpo�CTBa\\n(Smart Switch)\\n24 On�caH�e �yHK��� �KpaHa\\n32 �aHe�b yBeAoM�eH�� HacTpo�K�\\n33 BBOA TeKCTa BBe�eH�e\\n66\\n66 Samsung account\\n66 �o�K����eH��\\n�p��o�eH�� N �YHKUNN 68 Wi-Fi\\n69 Bluetooth\\n36 ycTaHOBKa N y�a�eH�e np��o�eH��\\n70 �KOHOM�� Tpa����\\n37 Te�e⌀oH\\n71 To�bKO MOO��bHble �aHHble\\n40 KOHTaKTbI\\n71 Mo6��bHa� TO4Ka �ocTyna\\n42 Coo6�eH��', additional_kwargs={}, response_metadata={})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.messages[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqYuo2PYrrhz"
      },
      "source": [
        "- 이점 및 활용\n",
        "    - 시스템 메시지는 모델에게 일관된 행동 방식을 부여하여, 사용자가 어떤 질문을 하든 모델이 동일한 스타일로 응답할 수 있도록 합니다. 이를 통해 모델의 응답 품질과 일관성을 높일 수 있습니다.\n",
        "    - 사용자 메시지는 동적인 질문을 포함하여, 모델이 실제로 대화의 흐름을 따르도록 만듭니다. 사용자가 원하는 작업이나 정보가 무엇인지 명확히 전달할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ulRllZwxXoR"
      },
      "source": [
        "### 1.4 chain으로 component 연결\n",
        "\n",
        "앞서 다뤘던 LLM과 ChatPromptTemplate를 연결하기 위해 **LangChain Expression Language (LCEL)** 표현식을 사용하려합니다.\n",
        "> LangChain Expression Language (LCEL)란?\n",
        "<br>LangChain에서 모델을 실행하거나 여러 컴포넌트를 결합할 때 사용하는 표현 방식입니다. LCEL을 사용하면 정의된 프롬프트 템플릿과 LLM을 연결하여 더 동적인 모델 실행을 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AsqR6aUexxmn"
      },
      "outputs": [],
      "source": [
        "chain = prompt_template | llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usq3w_Kz955a"
      },
      "source": [
        "정의된 chain을 `get_graph()` 메서드와 `draw_mermaid_png()` 메서드를 활용하여 chain의 구성을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "vFyOm_Gi0GFY",
        "outputId": "70c90aa4-7d12-4d37-aac0-9a684b1287b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(chain.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLKMAWX37cN_"
      },
      "source": [
        "invoke() 메서드는 **LLMChain**을 실행할 때 사용되며, 템플릿에 전달할 입력 데이터를 **딕셔너리 타입(dict)**로 전달합니다. 이 입력 딕셔너리에는 프롬프트 템플릿에서 정의한 변수들이 포함되며, 각 변수에 대한 실제 값이 key-value 쌍으로 제공됩니다. 이 방식은 동적으로 값을 채워 넣어 유연하게 템플릿을 실행할 수 있게 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v7jQCwMY0B_E"
      },
      "outputs": [],
      "source": [
        "response = chain.invoke({\"page_content\": docs[1],\n",
        "                         \"document_title\": sample_data['product_name']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYh7DIfWDAdc",
        "outputId": "4394e21d-c043-4720-b95b-1d3f26d45401"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"질문 1: 제품 매뉴얼에 언급된 'Smart Lock'은 무엇을 의미하나요?\\n답변: 'Smart Lock'은 일반적으로 디지털 보안 시스템의 일부로, 사용자가 비밀번호나 생체 인식 등을 통해 장치에 접근할 수 있게 해주는 기능을 의미합니다. 이 제품은 아마도 스마트 홈 장치와 연동하여 보안을 강화하는 기능을 제공할 것입니다.\\n\\n질문 2: 'Samsung Cloud'와 'Google'은 제품과 어떤 관련이 있나요?\\n답변: 'Samsung Cloud'와 'Google'은 클라우드 서비스 제공업체로, 이 제품은 이들 클라우드 서비스와 연동하여 데이터 저장, 백업, 동기화 등의 기능을 제공할 수 있습니다. 사용자는 클라우드 서비스를 통해 데이터를 안전하게 저장하고 어디서든 접근할 수 있습니다.\\n\\n질문 3: 'ycTpoCTBa'와 'ycTpocTBa'는 어떤 기능을 나타내나요?\\n답변: 이 두 용어는 제품의 특정 기능이나 구성 요소를 나타낼 수 있습니다. 정확한 의미는 제품의 모델이나 버전에 따라 다를 수 있으며, 매뉴얼의 다른 부분이나 공식 웹사이트에서 자세한 설명을 찾아볼 수 있습니다.\\n\\n질문 4: 'CBeeH o Tee⌀oHepoeHe'는 무엇을 의미하나요?\\n답변: 이 용어는 제품의 특정 기능이나 설정을 나타낼 수 있습니다. 정확한 의미는 제품의 모델이나 사용 언어에 따라 다를 수 있으며, 매뉴얼의 다른 부분이나 공식 웹사이트에서 자세한 설명을 찾아볼 수 있습니다.\\n\\n질문 5: 'HeoaoK3OCHOBHble CBeeH o6'는 어떤 기능을 나타내나요?\\n답변: 이 용어는 제품의 특정 기능이나 구성 요소를 나타낼 수 있습니다. 정확한 의미는 제품의 모델이나 버전에 따라 다를 수 있으며, 매뉴얼의 다른 부분이나 공식 웹사이트에서 자세한 설명을 찾아볼 수 있습니다.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 413, 'prompt_tokens': 756, 'total_tokens': 1169, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'solar-pro', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--b8c56dfa-312a-4a4e-8426-0bedbc4541da-0')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "m2xT9w9eDAYz",
        "outputId": "7e3003ce-cec5-46ba-f358-9761fb6a5271"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"질문 1: 제품 매뉴얼에 언급된 'Smart Lock'은 무엇을 의미하나요?\\n답변: 'Smart Lock'은 일반적으로 디지털 보안 시스템의 일부로, 사용자가 비밀번호나 생체 인식 등을 통해 장치에 접근할 수 있게 해주는 기능을 의미합니다. 이 제품은 아마도 스마트 홈 장치와 연동하여 보안을 강화하는 기능을 제공할 것입니다.\\n\\n질문 2: 'Samsung Cloud'와 'Google'은 제품과 어떤 관련이 있나요?\\n답변: 'Samsung Cloud'와 'Google'은 클라우드 서비스 제공업체로, 이 제품은 이들 클라우드 서비스와 연동하여 데이터 저장, 백업, 동기화 등의 기능을 제공할 수 있습니다. 사용자는 클라우드 서비스를 통해 데이터를 안전하게 저장하고 어디서든 접근할 수 있습니다.\\n\\n질문 3: 'ycTpoCTBa'와 'ycTpocTBa'는 어떤 기능을 나타내나요?\\n답변: 이 두 용어는 제품의 특정 기능이나 구성 요소를 나타낼 수 있습니다. 정확한 의미는 제품의 모델이나 버전에 따라 다를 수 있으며, 매뉴얼의 다른 부분이나 공식 웹사이트에서 자세한 설명을 찾아볼 수 있습니다.\\n\\n질문 4: 'CBeeH o Tee⌀oHepoeHe'는 무엇을 의미하나요?\\n답변: 이 용어는 제품의 특정 기능이나 설정을 나타낼 수 있습니다. 정확한 의미는 제품의 모델이나 사용 언어에 따라 다를 수 있으며, 매뉴얼의 다른 부분이나 공식 웹사이트에서 자세한 설명을 찾아볼 수 있습니다.\\n\\n질문 5: 'HeoaoK3OCHOBHble CBeeH o6'는 어떤 기능을 나타내나요?\\n답변: 이 용어는 제품의 특정 기능이나 구성 요소를 나타낼 수 있습니다. 정확한 의미는 제품의 모델이나 버전에 따라 다를 수 있으며, 매뉴얼의 다른 부분이나 공식 웹사이트에서 자세한 설명을 찾아볼 수 있습니다.\""
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLwM7o_HECYT"
      },
      "source": [
        "chain을 통해 얻은 문자열은 구조화가 되어 있는 데이터 유형이 아니기 때문에 별다른 처리가 필요해보입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrAPW7XHEZJY"
      },
      "source": [
        "### 1.5 prompt 강화\n",
        "이번 코드에서는 **JSON 포맷팅**을 사용하여 모델의 응답을 **구조화된 형태**로 생성하는 방법을 소개하고 있습니다. JSON 포맷팅은 데이터를 체계적으로 정리하고, 모델의 응답을 자동으로 처리하거나 후속 작업에 활용할 수 있게 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "um3HjnDm0F9h"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"{document_title} 중 한 페이지를 받게된다. 이를 읽고 사용자들이 질문할 만한 질문과 이에 대한 답변을 주어진 정보를 기반하여 만들어라.\n",
        "단 아래의 JSON format에 맞게 응답해야한다.\n",
        "\n",
        "quesion and answer are in Korean.\n",
        "```JSON\n",
        "[\n",
        "    {{\n",
        "        \"question\": str, # 사용자의 질문\n",
        "        \"answer\": str # 질문에 대한 응답\n",
        "    }}\n",
        "]\n",
        "```\n",
        "(주어진 정보가 질문하기에 충분하지 않다면 빈 list를 반환하라)\n",
        "\"\"\"\n",
        "user_prompt = \"\"\"제품 매뉴얼 : {page_content}\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", user_prompt)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9B4SQ1MiGdOm"
      },
      "outputs": [],
      "source": [
        "# 새롭게 정의된 prompt를 chain에 적용\n",
        "chain = prompt_template | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fZld6MdGGfZD"
      },
      "outputs": [],
      "source": [
        "response = chain.invoke({\"page_content\": docs[1], \"document_title\": title})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "3YNBhdZ0Gimc",
        "outputId": "8ef83048-b5b1-4e92-88ae-47625d479841"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'```json\\n[]\\n``` \\n'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex8-FmAGTEGt"
      },
      "source": [
        "JsonOutputParser는 LangChain에서 JSON 형식의 데이터를 쉽게 처리하고 파싱할 수 있는 도구입니다. JsonOutputParser는 모델의 응답을 JSON 형식으로 파싱하여, 결과를 명확하고 구조화된 형태로 변환하는 데 사용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "T7k6o7VuIJN_"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "parser = JsonOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mJauNAwIOE2",
        "outputId": "2f17a3ae-d9ff-4fe9-b80e-f5be91848d19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json_data = parser.parse(response.content)\n",
        "json_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OGS2JwadaP8W"
      },
      "outputs": [],
      "source": [
        "# parser 또한 chain으로 구성할 수 있습니다.\n",
        "chain = prompt_template | llm | parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_GAZ_1L6vaE"
      },
      "source": [
        "##2. 고객 사용 사례를 반영한 질문 유형화 실습\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bu7PBsFSlp9"
      },
      "source": [
        "### 2.1 Top-down 고객 사용 사례기반 분류\n",
        "이론시간에 *다룬 고객의 사용 사례 기반 서비스 디자인* 내용 중 질문 유형 분류에 필요성과 사용자 사례를 Top-down접근하여 사용자 사례의 대분류를 만들었습니다. 이를 기반으로 질의의 분류를 함께 할 수 있도록 prompt를 업데이트하여 결과를 받아보도록 합시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DdlUVQAN7sTu"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"{document_title} 중 한 페이지를 받게된다. 이를 읽고 사용자들이 질문할 만한 질문과 이에 대한 답변을 주어진 정보를 기반하여 만들어라.\n",
        "단 아래의 JSON format에 맞게 응답해야한다.\n",
        "\n",
        "(주어진 정보가 질문하기에 충분하지 않다면 빈 list를 반환하라)\n",
        "질문과 답변은 한국어로 작성해야 한다.\n",
        "\n",
        "질문과 답변은 다음과 같은 카테고리로 분류된다:\n",
        "1. '문제 해결' - 제품 사용 중 발생할 수 있는 문제를 해결하는 질문\n",
        "2. '제품 사용법 이해' - 제품 사용법과 관련된 질문\n",
        "3. '정보 탐색 및 선택' - 제품에 대한 정보나 선택과 관련된 질문\n",
        "\n",
        "```JSON\n",
        "[\n",
        "    {{\n",
        "        \"question\": str, # 사용자의 질문\n",
        "        \"answer\": str, # 질문에 대한 응답\n",
        "        \"category\": str # 질문의 카테고리 ('문제 해결', '제품 사용법 이해', '정보 탐색 및 선택', ...)\n",
        "    }}\n",
        "]\n",
        "\"\"\"# ⭐ system_prompt, user_prompt를 변경하여 결과 값이 어떻게 변하는지 확인하여 만족하는 prompt를 찾아보세요 (아래 [참고 자료]의 prompt 가이드를 보고 최적화 해보세요)\n",
        "user_prompt = \"\"\"제품 매뉴얼 : {page_content}\"\"\"# ⭐\n",
        "\n",
        "prompt_template = ChatPromptTemplate([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", user_prompt)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvGX8rNZFwvT"
      },
      "source": [
        "#### [참고자료]\n",
        "아래 참고 자료들은 Solar LLM prompt 가이드 입니다.\n",
        "- [Role and Style Prompting](https://github.com/UpstageAI/solar-prompt-cookbook/blob/main/05_Chapter%205.%20Role%20and%20Style%20Prompting.ipynb)\n",
        "\n",
        "- [Unstructured vs. Structured Prompting](https://github.com/UpstageAI/solar-prompt-cookbook/blob/main/06_Chapter%206.%20Unstructured%20vs.%20Structured%20Prompting.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeERSuzScGCs"
      },
      "source": [
        "아래 코드는 LangChain의 Output Parser 기능을 사용하여 LLM의 출력에서 발생할 수 있는 에러를 자동으로 수정하기 위한 설정을 추가한 예시입니다.\n",
        "\n",
        "- OutputFixingParser는 LLM 출력이 주어진 형식에 맞지 않거나 오류가 발생했을 때 이를 수정하는 역할을 합니다.\n",
        "- fix_parser는 기존의 parser와 LLM을 기반으로 생성되며, 오류가 감지될 경우 LLM을 다시 호출하여 형식을 보정합니다.\n",
        "- 마지막 줄의 chain에 fix_parser를 추가함으로써, 입력에서 출력으로 이어지는 파이프라인에 오류 복구 기능을 통합합니다.\n",
        "\n",
        "이 설정은 에러 처리 자동화를 통해 사용자 경험을 향상시키고, 출력의 일관성을 유지하는 데 유용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6obdtvkub3os"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import OutputFixingParser\n",
        "fix_parser = OutputFixingParser.from_llm(parser=parser, llm=llm, max_retries=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "N5SI8mTHMvFc"
      },
      "outputs": [],
      "source": [
        "chain = prompt_template | llm | fix_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "188AbhXfM4NA"
      },
      "outputs": [],
      "source": [
        "response = chain.invoke({\"page_content\": docs[10], \"document_title\": title})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL7LTIkyM606",
        "outputId": "f4489d48-cb01-4bb8-cc03-2093079ba27e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': '갤럭시 Z 폴드3의 매뉴얼을 어떻게 읽을 수 있나요?',\n",
              "  'answer': '매뉴얼은 제품과 함께 제공되는 종이 매뉴얼이나 Samsung Members 앱에서 확인할 수 있습니다.',\n",
              "  'category': '정보 탐색 및 선택'},\n",
              " {'question': \"갤럭시 Z 폴드3의 매뉴얼에서 'COb3OBaH'는 무슨 뜻인가요?\",\n",
              "  'answer': '이는 매뉴얼의 일부가 잘못 표시된 것으로 보입니다. 정확한 정보를 얻으려면 Samsung Members 앱이나 Samsung 공식 웹사이트를 참조하세요.',\n",
              "  'category': '정보 탐색 및 선택'},\n",
              " {'question': \"갤럭시 Z 폴드3의 매뉴얼에서 'npoeH'는 무슨 뜻인가요?\",\n",
              "  'answer': '이는 매뉴얼의 일부가 잘못 표시된 것으로 보입니다. 정확한 정보를 얻으려면 Samsung Members 앱이나 Samsung 공식 웹사이트를 참조하세요.',\n",
              "  'category': '정보 탐색 및 선택'},\n",
              " {'question': \"갤럭시 Z 폴드3의 매뉴얼에서 'COb30BaH'는 무슨 뜻인가요?\",\n",
              "  'answer': '이는 매뉴얼의 일부가 잘못 표시된 것으로 보입니다. 정확한 정보를 얻으려면 Samsung Members 앱이나 Samsung 공식 웹사이트를 참조하세요.',\n",
              "  'category': '정보 탐색 및 선택'}]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhYzQKdGcJCE"
      },
      "source": [
        "아래 코드의 일부분은 제품 이름(product_name)이 누락된 경우 이를 자동으로 추출하기 위해 다른 PDF 문서에서 가져온 제품 이름 리스트를 활용하여 Few-shot Prompt를 적용한 사례입니다.\n",
        "\n",
        "1.\t제품 이름 리스트 활용:\n",
        "    - product_name_list는 다른 PDF에서 사전 추출된 제품 이름들의 예시입니다.\n",
        "    - Few-shot Prompt에서 예제 역할을 하여 LLM이 보다 정확히 제품 이름을 추출할 수 있도록 돕습니다.\n",
        "2.\t첫 페이지 기반 추출:\n",
        "    - 제품 매뉴얼의 첫 페이지(docs[0])는 보통 제품 이름이 포함되어 있으므로, 이를 Prompt에 포함시켜 LLM으로부터 제품 이름을 추출합니다.\n",
        "3.\tPrompt 템플릿 설계:\n",
        "    - extract_product_name_template은 두 부분으로 구성됩니다:\n",
        "    - System 메시지: 제품 이름 추출에 대한 명령과 예제를 제공.\n",
        "    - User 메시지: 실제 매뉴얼의 첫 페이지 내용을 전달.\n",
        "4.\t자동화된 이름 추출:\n",
        "    - extract_product_name_chain을 통해 첫 페이지 내용을 입력으로 사용하고, 누락된 product_name 값을 자동으로 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6iTvsUU4pkyQ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# 추후 사용하는 데이터 품질 평가를 위해 사용한 context(doc)를 추가하는 작업을 위해 다음과 같은 함수를 정의합니다.\n",
        "def loop_chain_docs(chain, docs, data, product_name_list, debug_mode=False, batch_procecss=True):\n",
        "\n",
        "    # product_name이 없는 경우\n",
        "    if data[\"product_name\"] == \"\":\n",
        "        extract_product_name_template = ChatPromptTemplate([\n",
        "        (\"system\", \"\"\"Extract product_name from [first page]\n",
        "\n",
        "### few-shot example\n",
        "{product_name_list}\n",
        "\n",
        "YOU MUST ANSWER ONLY PRODUCT NAME!!\n",
        "DO NOT TRANSLATE PRODUCT NAME INTO OTHER LANGUAGE\n",
        "answer like \"Samsung Galaxy S10 Lite (128GB)\"\n",
        "\"\"\"),\n",
        "        (\"user\", \"\"\"first page : {first_page}\"\"\")\n",
        "    ])\n",
        "        llm = SolarChat(temperature=0.0)\n",
        "        extract_product_name_chain = extract_product_name_template | llm\n",
        "        # 보통 첫번째 페이지에서 \"제품 이름\"이 있으니 첫번째 docs만 이용하여 \"제품 이름\"을 추출\n",
        "        response = extract_product_name_chain.invoke({\"product_name_list\": product_name_list, \"first_page\": docs[0]})\n",
        "        data[\"product_name\"] = response.content\n",
        "\n",
        "    if debug_mode:\n",
        "        # random sample 20%\n",
        "        docs = random.sample(docs, int(len(docs) * 0.20))\n",
        "\n",
        "    if batch_procecss:\n",
        "        batch_docs = [{\"page_content\": doc, \"document_title\": data[\"product_name\"]} for doc in docs if doc]\n",
        "        batch_response = chain.batch(batch_docs, config={\"max_concurrency\": 10})\n",
        "        result = []\n",
        "        for batch_item, doc in zip(batch_response, docs):\n",
        "            if isinstance(batch_item, list):\n",
        "                for item in batch_item:\n",
        "                    item[\"context\"] = doc\n",
        "                    item[\"product_name\"] = data[\"product_name\"]\n",
        "                    # result.extend(batch_item)   # 기존코드\n",
        "                    result.append(item)   # 실제로 돌아갔어야 할 코드\n",
        "            elif batch_item is not None:\n",
        "                batch_item[\"context\"] = doc\n",
        "                batch_item[\"product_name\"] = data[\"product_name\"]\n",
        "                result.append(batch_item)\n",
        "        return result\n",
        "    else:\n",
        "        result = []\n",
        "        for doc in docs:\n",
        "            response = chain.invoke({\"page_content\": doc, \"document_title\": data[\"product_name\"]})\n",
        "            for item in response:\n",
        "                item[\"context\"] = doc\n",
        "                item[\"product_name\"] = data[\"product_name\"]\n",
        "            result.extend(response)\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in /opt/miniconda3/lib/python3.13/site-packages (8.1.7)\n",
            "Requirement already satisfied: comm>=0.1.3 in /opt/miniconda3/lib/python3.13/site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /opt/miniconda3/lib/python3.13/site-packages (from ipywidgets) (9.3.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /opt/miniconda3/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/miniconda3/lib/python3.13/site-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/miniconda3/lib/python3.13/site-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: decorator in /opt/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in /opt/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /opt/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /opt/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /opt/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /opt/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: stack_data in /opt/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in /opt/miniconda3/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/miniconda3/lib/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda3/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda3/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda3/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure_eval in /opt/miniconda3/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install ipywidgets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9897e9fce04a4588a62c8ea7eabc81c4",
            "2f413baf36c34f3e9aafe856deb0fe61",
            "a195be17296744539ca585fc43f32a2d",
            "0e34ae80dfe5420385ade163e6d8b99f",
            "19bdcfa61dae4bed999fc99ae17cbccb",
            "2380397d3f9149c995abb252d5d9f3fc",
            "4caf80e10cbe4bde955d8b0c9f47edfc",
            "3d5e6910792345389026848189cb99ff",
            "d0f2c80a45ca4bf0a3256d4a8a46b0b6",
            "513ccb57ddcb4fd8be5e29f38a73ee3a",
            "501b062c7a50416bb06110a816757006"
          ]
        },
        "id": "T3aac2PqqdK5",
        "outputId": "231898ae-9715-4035-ae0d-649a64e3cc9c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0063328db9c4491bba3ea084787ad69e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': \"You've reached your API request limit. Please wait and try again later. If your use case requires a higher rate limit, you can request an increase at https://support.upstage.ai. Including your intended use case and expected volume will help us process your request faster\", 'type': 'too_many_requests', 'param': '', 'code': 'too_many_requests'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      7\u001b[39m text_splitter = RecursiveCharacterTextSplitter(\n\u001b[32m      8\u001b[39m     chunk_size=\u001b[32m2048\u001b[39m,\n\u001b[32m      9\u001b[39m     chunk_overlap=\u001b[32m10\u001b[39m,\n\u001b[32m     10\u001b[39m     length_function=\u001b[38;5;28mlen\u001b[39m,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m docs = text_splitter.split_text(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(data[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m result = \u001b[43mloop_chain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_name_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_procecss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m qa_dataset.extend(result)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mloop_chain_docs\u001b[39m\u001b[34m(chain, docs, data, product_name_list, debug_mode, batch_procecss)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_procecss:\n\u001b[32m     30\u001b[39m     batch_docs = [{\u001b[33m\"\u001b[39m\u001b[33mpage_content\u001b[39m\u001b[33m\"\u001b[39m: doc, \u001b[33m\"\u001b[39m\u001b[33mdocument_title\u001b[39m\u001b[33m\"\u001b[39m: data[\u001b[33m\"\u001b[39m\u001b[33mproduct_name\u001b[39m\u001b[33m\"\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs \u001b[38;5;28;01mif\u001b[39;00m doc]\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     batch_response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_concurrency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     result = []\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch_item, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_response, docs):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_core/runnables/base.py:3196\u001b[39m, in \u001b[36mRunnableSequence.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m   3194\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3195\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps):\n\u001b[32m-> \u001b[39m\u001b[32m3196\u001b[39m             inputs = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3197\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   3199\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# each step a child run of the corresponding root run\u001b[39;49;00m\n\u001b[32m   3200\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3201\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3202\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3203\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3204\u001b[39m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3205\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3206\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3207\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3209\u001b[39m \u001b[38;5;66;03m# finish the root runs\u001b[39;00m\n\u001b[32m   3210\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_core/runnables/base.py:797\u001b[39m, in \u001b[36mRunnable.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mlist[Output]\u001b[39m\u001b[33m\"\u001b[39m, [invoke(inputs[\u001b[32m0\u001b[39m], configs[\u001b[32m0\u001b[39m])])\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(configs[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mlist[Output]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_core/runnables/config.py:555\u001b[39m, in \u001b[36mContextThreadPoolExecutor.map.<locals>._wrapped_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_fn\u001b[39m(*args: Any) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontexts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_core/runnables/base.py:790\u001b[39m, in \u001b[36mRunnable.batch.<locals>.invoke\u001b[39m\u001b[34m(input_, config)\u001b[39m\n\u001b[32m    788\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m e\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_community/chat_models/openai.py:476\u001b[39m, in \u001b[36mChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m    470\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    471\u001b[39m params = {\n\u001b[32m    472\u001b[39m     **params,\n\u001b[32m    473\u001b[39m     **({\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m    474\u001b[39m     **kwargs,\n\u001b[32m    475\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/langchain_community/chat_models/openai.py:387\u001b[39m, in \u001b[36mChatOpenAI.completion_with_retry\u001b[39m\u001b[34m(self, run_manager, **kwargs)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m retry_decorator = _create_retry_decorator(\u001b[38;5;28mself\u001b[39m, run_manager=run_manager)\n\u001b[32m    391\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_completion_with_retry\u001b[39m(**kwargs: Any) -> Any:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': \"You've reached your API request limit. Please wait and try again later. If your use case requires a higher rate limit, you can request an increase at https://support.upstage.ai. Including your intended use case and expected volume will help us process your request faster\", 'type': 'too_many_requests', 'param': '', 'code': 'too_many_requests'}}"
          ]
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm_notebook\n",
        "product_name_list = [data[\"product_name\"] for data in data_list if data[\"product_name\"]]\n",
        "\n",
        "qa_dataset = []\n",
        "for data in tqdm_notebook(data_list):  # 일반적으로 문서 1개 당 약 1-2분 소요\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=2048,\n",
        "        chunk_overlap=10,\n",
        "        length_function=len,\n",
        "    )\n",
        "    docs = text_splitter.split_text(\"\".join(data[\"content\"]))\n",
        "\n",
        "    result = loop_chain_docs(chain, docs, data, product_name_list, debug_mode=False, batch_procecss=True)\n",
        "    qa_dataset.extend(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P66jnsgjW5i"
      },
      "source": [
        "## 3. 데이터셋 정제 및 품질 평가 실습\n",
        "\n",
        "LLM으로 생성된 QA 데이터셋을 정제하고 품질을 평가하는 단계입니다.\n",
        "\n",
        "이 단계에서는 다음과 같은 작업을 수행합니다.\n",
        "\n",
        "1. 데이터 정제: LLM이 생성한 QA 데이터셋에서 구조화되지 않거나 적절하지 않은 데이터들을 제거합니다.\n",
        "    - 예를 들어, JSON 형식에 맞지 않는 데이터, 필요한 필드가 누락된 데이터 식별하고 제거합니다.\n",
        "\n",
        "2. 중복 제거: `TfidfVectorizer`와 코사인 유사도를 사용하여 중복 질문과 답변을 제거합니다.\n",
        "    - `deduplicate_df` 함수는 데이터프레임에서 중복된 질문과 답변 쌍을 식별하고 제거합니다.\n",
        "    - `recursive_deduplicate` 함수는 데이터프레임을 여러 윈도우로 분할하여 각 윈도우에서 중복 제거를 반복 적용하여 더욱 효과적으로 중복을 제거합니다.\n",
        "\n",
        "3. 품질 평가: 정제된 데이터셋을 시각화하여 생성된 QA 데이터의 질의 카테고리 분포를 확인합니다.\n",
        "\n",
        "    - 다양한 시각화 도구(예: matplotlib, seaborn)를 사용하여 카테고리별 데이터 수, 비율 등을 분석합니다.\n",
        "    - 이를 통해 데이터셋의 균형성, 다양성, 편향 등을 파악하고 개선 방향을 설정할 수 있습니다.\n",
        "\n",
        "이러한 정제 및 평가 과정을 통해 최종적으로 높은 품질의 QA 데이터셋을 구축하고, 이를 기반으로 효과적인 QA 챗봇 등의 서비스를 개발할 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjtZDuxzonok"
      },
      "source": [
        "### 3.1 데이터 정제\n",
        "이 섹션에서는 LLM으로 생성된 QA 데이터셋에서 구조화되지 않거나 적절하지 않은 데이터들을 제거하는 방법을 설명합니다.\n",
        "\n",
        "작업 내용:\n",
        "\n",
        "1. 데이터프레임 변환: 생성된 QA 데이터셋을 Pandas DataFrame으로 변환합니다. 이를 통해 데이터를 보다 쉽게 조작하고 분석할 수 있습니다.\n",
        "2. 값 확인: DataFrame에서 누락된 값(NaN)이 있는지 확인합니다. `isna().sum()` 메서드를 사용하여 각 열에 누락된 값의 개수를 확인합니다.\n",
        "3. 약속되지 않은 결과물 제거: 필요한 필드가 누락된 데이터를 제거합니다. 예를 들어, 'question', 'answer', 'category', 'context', 'product_name' 열에 값이 없는 행을 삭제합니다.\n",
        "4. 누락 값 재확인: 데이터 정제 후 다시 한번 누락된 값이 있는지 확인합니다. `isna().sum()` 메서드를 사용하여 누락된 값이 없는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1BFjS55QBek"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyD6FIQC5GdY"
      },
      "outputs": [],
      "source": [
        "# pandas dataframe으로 변형\n",
        "df = pd.DataFrame(qa_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ioKg2gCl5FR4",
        "outputId": "07ec191c-e8cb-4234-c40d-7ef34898faf5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>question</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "question         3\n",
              "answer           7\n",
              "category        19\n",
              "context          0\n",
              "product_name     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 값 확인\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pukNiYgt2yfR"
      },
      "outputs": [],
      "source": [
        "# 약속되지 않은 결과물은 삭제\n",
        "df = df[['question', 'answer', 'category', 'context', 'product_name']].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "wiTMxkNt3xTg",
        "outputId": "839d9d1e-b2f6-48d6-96a0-140ff5350d55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>question</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "question        0\n",
              "answer          0\n",
              "category        0\n",
              "context         0\n",
              "product_name    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "couv0V48oiua"
      },
      "source": [
        "### 3.2 중복 제거\n",
        "이 섹션에서는 TfidfVectorizer와 코사인 유사도를 사용하여 중복 질문과 답변을 제거하는 방법을 설명합니다.\n",
        "\n",
        "작업 내용:\n",
        "1. TF-IDF 벡터화: TfidfVectorizer를 사용하여 질문과 답변을 벡터화합니다. TF-IDF는 텍스트에서 단어의 중요도를 나타내는 수치적 표현입니다.\n",
        "2. 코사인 유사도 계산: 벡터화된 질문과 답변 사이의 코사인 유사도를 계산합니다. 코사인 유사도는 두 벡터 사이의 유사성을 측정하는 지표입니다.\n",
        "3. 중복 인덱스 저장: 코사인 유사도가 특정 임계값(예: 0.7)보다 높은 질문과 답변 쌍을 중복으로 간주하고 해당 인덱스를 저장합니다.\n",
        "4. 중복 제거: 중복 인덱스를 기반으로 DataFrame에서 중복된 행을 제거합니다.\n",
        "5. 재귀적 중복 제거: 데이터프레임을 여러 윈도우로 분할하여 각 윈도우에서 중복 제거를 반복 적용합니다. 이를 통해 더욱 효과적으로 중복을 제거할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0pAMnkWmCxW"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def deduplicate_df(df, threshold=0.7):\n",
        "\n",
        "    questions = [q + a for q, a  in df[[\"question\", \"answer\"]].values]\n",
        "\n",
        "    # TF-IDF 벡터화\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(questions)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    # 중복 인덱스 저장\n",
        "    duplicate_indices = set()\n",
        "    for idx in range(len(questions)):\n",
        "        if idx in duplicate_indices:\n",
        "            continue\n",
        "        sims = cosine_sim[idx]\n",
        "        similar_indices = np.where(sims > threshold)[0]\n",
        "        for sim_idx in similar_indices:\n",
        "            if sim_idx != idx:\n",
        "                duplicate_indices.add(sim_idx)\n",
        "    deduplicated_qa_list = [idx for idx, _ in enumerate(df[[\"question\", \"answer\"]].values) if idx not in duplicate_indices]\n",
        "    return df.iloc[deduplicated_qa_list]\n",
        "\n",
        "def recursive_deduplicate(df, n=2, window_size=128, threshold=0.7):\n",
        "    \"\"\"데이터프레임에서 중복된 질문과 답변 쌍을 재귀적으로 제거합니다.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): 중복 제거를 수행할 데이터프레임.\n",
        "        n (int, optional): 재귀 횟수. 기본값은 2입니다.\n",
        "        window_size (int, optional): 데이터프레임을 분할할 윈도우 크기. 기본값은 128입니다.\n",
        "        threshold (float, optional): 중복으로 간주할 코사인 유사도 임계값. 기본값은 0.7입니다.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 중복 제거된 데이터프레임.\n",
        "    \"\"\"\n",
        "    deduplicated_qa_list = []\n",
        "    # suffle df\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    for i in range(0, len(df), window_size):\n",
        "        df_window = df.iloc[i:i+window_size]\n",
        "        deduplicated_qa_list.append(deduplicate_df(df_window, threshold=threshold))\n",
        "    if n > 1:\n",
        "        return recursive_deduplicate(pd.concat(deduplicated_qa_list), n-1, window_size)\n",
        "    return pd.concat(deduplicated_qa_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9dagkdIVeBD"
      },
      "outputs": [],
      "source": [
        "sample_product_name = df.product_name.unique()[0]\n",
        "sub_sample_df = df.loc[df.product_name == sample_product_name]\n",
        "\n",
        "# ⭐ 중복 제거로 대상이 되는 값이 질문인 경우와 질문과 답변을 같이 사용한 경우\n",
        "#    제거가 되는 값(n 시행횟수)이 어떻게 변하는지 확인하고 유사도(threshold)를 변경하였을 때의 경향성을 확인해보세요\n",
        "#    (n, window_size, threshold) 값에 따라서 어떻게 변하는지 확인해보세요\n",
        "dedu_df = recursive_deduplicate(df, n=2, window_size=32, threshold=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPNkYTrFuit1",
        "outputId": "9911285c-aed9-4487-9570-95641a9b7eb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9950556242274413"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dedu_df) / len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s32QLmGElBoL"
      },
      "source": [
        "### 3.3 품질 평가\n",
        "이 섹션에서는 정제된 데이터셋을 시각화하여 생성된 QA 데이터의 질의 카테고리 분포를 확인하는 방법을 설명합니다.\n",
        "\n",
        "작업 내용:\n",
        "1. 카테고리별 데이터 수 확인: `value_counts()` 메서드를 사용하여 각 카테고리에 속하는 데이터의 개수를 확인합니다.\n",
        "2. 원형 차트 생성: matplotlib 또는 seaborn 라이브러리를 사용하여 카테고리별 데이터 수를 원형 차트로 시각화합니다.\n",
        "3. 분포 분석: 원형 차트를 통해 데이터셋의 균형성, 다양성, 편향 등을 파악합니다.\n",
        "4. 개선 방향 설정: 분석 결과를 바탕으로 데이터셋의 품질을 개선하기 위한 방향을 설정합니다. 예를 들어, 특정 카테고리에 데이터가 부족한 경우 해당 카테고리의 데이터를 추가적으로 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "eAUQ6lCCxWK8",
        "outputId": "9bb8a795-1da6-43ec-f1f2-bae584f29214"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import koreanize_matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# how many category in dataframe\n",
        "num_cat = dedu_df.category.nunique()\n",
        "\n",
        "# define Seaborn color palette to use\n",
        "colors = sns.color_palette('pastel')[0:num_cat]\n",
        "dedu_df.category.value_counts()\n",
        "# create pie chart\n",
        "plt.pie(x=dedu_df.category.value_counts().values,\n",
        "        labels=dedu_df.category.value_counts().index.values,\n",
        "        colors = colors,\n",
        "        autopct='%.0f%%')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJUHIpuL5iq5",
        "outputId": "bb31dad5-2964-4f30-9769-d92b5ff76969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3220"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dedu_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wmxN9o4eYoi"
      },
      "outputs": [],
      "source": [
        "json_data = []\n",
        "for i, entry in dedu_df.iterrows():\n",
        "    json_data.append({\n",
        "        \"question\": entry[\"question\"],\n",
        "        \"answer\": entry[\"answer\"],\n",
        "        \"category\": entry[\"category\"],\n",
        "        \"product_name\": entry[\"product_name\"],\n",
        "        \"context\": entry[\"context\"]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTX3BCqReeuV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Save as a single JSON file\n",
        "json_output_path = os.path.join(DATA_DIR, 'qa_dataset_full.json')\n",
        "with open(json_output_path, 'w', encoding='utf-8') as file:\n",
        "    json.dump(json_data, file, ensure_ascii=False, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ0GnL1BRRTs"
      },
      "outputs": [],
      "source": [
        "(pd.DataFrame(json_data)).to_excel(os.path.join(DATA_DIR, 'qa_dataset_full.xlsx'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzTVTmmSgror"
      },
      "source": [
        "## 4.0 로컬 환경에 `qa_dataset_full.json` 파일 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6YXoTiBCg4Cy",
        "outputId": "b7a3c070-75fe-45ac-a6d5-6383ab9fdd31"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_af031b66-f3ce-47ef-82bc-2f1998181ec6\", \"qa_dataset_full.json\", 7874737)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 다운로드 받을 파일 경로\n",
        "file_path = os.path.join(DATA_DIR, 'qa_dataset_full.json')\n",
        "\n",
        "# Download the file\n",
        "files.download(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SmC_R8ceSgq"
      },
      "source": [
        "## (Appendix) langchain의 `document_loaders` 사용해보기\n",
        "\n",
        "LangChain의 Document Loader는 다양한 문서 형식(PDF, 텍스트 파일, 웹 페이지 등)을 읽어들이고, 그 내용을 텍스트 데이터로 변환하여 처리할 수 있게 도와주는 유용한 도구입니다. 아래의 코드를 사용하여 LangChain에서 PDF 파일을 불러오는 방법을 설명하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpBbl-P5iMNg"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(os.path.join(DATA_DIR, \"z_fold3.pdf\"))\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEl-3grufUG9"
      },
      "source": [
        "설명:\n",
        "- `PyMuPDFLoader`: 이 클래스는 PyMuPDF 라이브러리를 사용하여 PDF 파일을 읽어옵니다. 이 문서 로더는 PDF 파일에서 텍스트를 추출하고 이를 LangChain에서 처리할 수 있는 형태로 변환합니다\n",
        "- `loader.load()`: 이 메서드는 지정된 경로의 PDF 파일을 로드하여 문서 내용이 포함된 리스트를 반환합니다. 각 문서는 텍스트 데이터로 변환되어 나열됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnSGbJCWf-3s"
      },
      "source": [
        "문서를 처리할 때, **metadata**는 문서에 대한 유용한 정보를 담고 있습니다. Langchain을 사용하여 문서를 로드할 때 마다, 해당 문서의 **metadata**를 확인할 수 있습니다. 이를 통해 파일의 제목, 페이지 수, 작성자, 생성일자 등 다양한 정보에 접근할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIcpuYYzkJa4",
        "outputId": "c39ceefe-a35e-46c6-e9e4-8fe953d680b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': '/content/z_fold3.pdf',\n",
              " 'file_path': '/content/z_fold3.pdf',\n",
              " 'page': 0,\n",
              " 'total_pages': 181,\n",
              " 'format': 'PDF 1.7',\n",
              " 'title': 'Samsung Galaxy Z Fold3|Z Flip3 5G F926|F711 User Manual',\n",
              " 'author': 'Samsung',\n",
              " 'subject': '',\n",
              " 'keywords': 'Samsung Galaxy Z Fold3|Z Flip3 5G; F926|F711; Samsung Galaxy Z Fold3|Z Flip3 5G F926|F711; Samsung Galaxy Z Fold3|Z Flip3 5G user guide; Samsung Galaxy Z Fold3|Z Flip3 5G manual; F926|F711 user guide; F926|F711 manual',\n",
              " 'creator': '',\n",
              " 'producer': '',\n",
              " 'creationDate': \"D:20211014152251-05'00'\",\n",
              " 'modDate': \"D:20211014152616-05'00'\",\n",
              " 'trapped': ''}"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVW7VnyvkWka",
        "outputId": "2cdd9d1c-5084-435a-e5d5-f9e769440aa6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "181"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9SmC_R8ceSgq"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e34ae80dfe5420385ade163e6d8b99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513ccb57ddcb4fd8be5e29f38a73ee3a",
            "placeholder": "​",
            "style": "IPY_MODEL_501b062c7a50416bb06110a816757006",
            "value": " 16/16 [18:24&lt;00:00, 77.72s/it]"
          }
        },
        "19bdcfa61dae4bed999fc99ae17cbccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2380397d3f9149c995abb252d5d9f3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f413baf36c34f3e9aafe856deb0fe61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2380397d3f9149c995abb252d5d9f3fc",
            "placeholder": "​",
            "style": "IPY_MODEL_4caf80e10cbe4bde955d8b0c9f47edfc",
            "value": "100%"
          }
        },
        "3d5e6910792345389026848189cb99ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4caf80e10cbe4bde955d8b0c9f47edfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "501b062c7a50416bb06110a816757006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "513ccb57ddcb4fd8be5e29f38a73ee3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9897e9fce04a4588a62c8ea7eabc81c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f413baf36c34f3e9aafe856deb0fe61",
              "IPY_MODEL_a195be17296744539ca585fc43f32a2d",
              "IPY_MODEL_0e34ae80dfe5420385ade163e6d8b99f"
            ],
            "layout": "IPY_MODEL_19bdcfa61dae4bed999fc99ae17cbccb"
          }
        },
        "a195be17296744539ca585fc43f32a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d5e6910792345389026848189cb99ff",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0f2c80a45ca4bf0a3256d4a8a46b0b6",
            "value": 16
          }
        },
        "d0f2c80a45ca4bf0a3256d4a8a46b0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
